
[{
  "url": "/",
  "section": "",
  "title": "MakinaStates documentation",
  "type": "page",
  "description": "",
  "content": "Welcome to the documentation of MakinaStates, the deployment framework Reference Installation Usage Dedicated topics Operating a cluster API",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/install/",
  "section": "install",
  "title": "Installation",
  "type": "install",
  "description": "",
  "content": "REMEMBER THAT FOR NOW YOU HAVE TO USE UBUNTU \u0026gt;= 14.04. Use root unless you understand well how it works to handle user install Download Get MakinaStates by cloning it from github Usually we install it in /srv/makina-states git clone http://raw.github.com/makinacorpus/makina-states /srv/makina-states Common install command Install with scratch node, with refresh cron, logrotate. bin,/boot-salt2.sh -C --install-logrotate --install-crons boot-salt2.sh, the makina-states installer \u0026amp; manager boot-salt2.sh will try to remember how you configured makina-states on each run. It stores configs in \u0026lt;clone_dir\u0026gt;/etc/makina-states You can see the help this way: bin/boot-salt2.sh --help # Short overview: bin/boot-salt2.sh --long-help # Detailed overview: If you want to install with default options (scratch) bin/boot-salt2.sh -C Optional post install steps Install the logrotate to rotate salt logs bin/boot-salt2.sh -C --install-logrotate Install the cron that refresh makina-states code every since and then (15min) bin/boot-salt2.sh -C --install-crons Install the salt \u0026amp; ansible binaries to /usr/local/bin. THIS IS NOT RECOMMENDED ANYMORE, AND EVEN HARMFULL bin/boot-salt2.sh -C --install-links Related documents Usage Layout database.sls nodetypes",
  "subtitle":"",
  "tags": ["installation","install","upgrade"]
  }
,{
  "url": "/usage/ansible/saltcall/",
  "section": "usage",
  "title": "Ansible saltcall module",
  "type": "usage",
  "description": "",
  "content": "saltcall Wrapper We developped a special module to call saltcall on remote systems. You can use it via ansible: ANSIBLE_TARGETS=$(hostname) bin/ansible all \\ -m saltcall -a \u0026quot;function=test.ping\u0026quot; ANSIBLE_TARGETS=$(hostname) bin/ansible all \\ -m saltcall -a \u0026quot;function=grains.get args=fqdn\u0026quot; Or via a playbook like in our saltcall one , usable this way: ANSIBLE_TARGETS=$(hostname) bin/ansible-playbook \\ ansible/plays/saltcall.yml -m saltcall -a \u0026quot;function=test.ping\u0026quot; It\u0026rsquo;s better to use the playbook because it call the makinastates_pillar role to copy locally on the remote box the pillar computed by the salt+pillar bridge before executing the salt command.",
  "subtitle":"",
  "tags": ["topics","ansible"]
  }
,{
  "url": "/usage/salt/",
  "section": "usage",
  "title": "Salt",
  "type": "usage",
  "description": "",
  "content": "Command log level Remember that -lall refers to the loglevel all. You can lower the output level by lowering down to info (-linfo). Run a salt state bin/salt-call -lall --retcode-passthrough state.sls \u0026lt;STATE\u0026gt; Run a salt function bin/salt-call -lall --retcode-passthrough test.ping Configure a pillar entry pillar/pillar.d/myentry.sls --- makina-states.foo.bar: bal",
  "subtitle":"",
  "tags": ["usage","salt"]
  }
,{
  "url": "/usage/ansible/",
  "section": "usage",
  "title": "Ansible",
  "type": "usage",
  "description": "",
  "content": "Leaving localhost When you want to execute saltstack states (makina-states) remotly, here is the prefligh list to do: declare your host in the database.sls Ensure that the target is reachable from ansible Bootstrap makina-states on the remote box, via the providen makinastates role Ansible wrappers specifics To use ansible, please use makina-states wrappers and never EVER the ansible original scripts directly. If you are using the database.sls, we use environment variables that are specific to makina-states and tell the ext pillar (local saltstack side) for which environment to gather information for. ANSIBLE_TARGETS : list of hosts that we will act on. this will limit the scope of the ext pillars generation thus you have to set it to speed up operations. ANSIBLE_NOLIMIT : if set, we wont limit the scope of ansible to ANSIBLE_TARGETS Examples exemple 1 ANSIBLE_TARGETS=$(hostname) bin/ansible all -m ping exemple 2 bin/ansible -c local -i \u0026quot;localhost,\u0026quot; all -m ping Examples with salt Call a state.sls run ANSIBLE_TARGETS=$(hostname) bin/ansible all -m shell \\ -a salt-call --retcode-passthrough state.sls foobar Details See: bin/ansible bin/ansible-galaxy bin/ansible-playbook bin/ansible-wrapper-common We preconfigure in our wrappers a lot of things like: Loading configuration (roles, playbooks, inventories, plugins) from: ./ ./ansible ./.ansible \u0026lt;makinastates_install_dir\u0026gt;/ansible /usr/share/ansible (depends of the opt, respects the ansible default configuration) /etc/ansible (depends of the opt, respects the ansible default configuration) When ANSIBLE_TARGETS are set, we will limit the play to them unless ANSIBLE_NOLIMIT is set. Calling makina-states\u0026rsquo;s flavored ansible from another repository As said previously, we load the current folder (and ./.ansible, ./ansible as well). This clever trick will let you can add roles and plays to a specific repository but also be able to depend on plugins or roles defined in makina-states. This mean that you ll be able to call the ansible wrapper FROM your directory where you have your specific ansible installation and the whole will assemble nicely. For example: if makina-states is installed in /srv/makina-states your project is installed inside /srv/projects/foo/project You can create your roles inside /srv/projects/foo/project/ansible/roles You can make dependencies of any makina-states roles specially makinastates_pillar that deploy the locally gather pillar for a box to the remote if you are not acting on localhost. You ll have to call ansible or ansible-playbook, do it this way: cd /srv/projects/foo/project /srv/makina-states/bin/{ansible,ansible-playbook} $args Related salt call module",
  "subtitle":"",
  "tags": ["usage","ansible"]
  }
,{
  "url": "/reference/sumup/",
  "section": "reference",
  "title": "Order of operation",
  "type": "reference",
  "description": "",
  "content": "Organisation \u0026amp; Workflow makina-states primarely use salt to deploy on the targeted environment. Our salt states are thought to be used in a special order, and specially when you call salt via the sls: makina-states.top. We apply first the nodetype configuration. Then, we will apply the controllers configuration. Then, we will apply localsettings states After all of the previous steps, we may configure services like sshd, crond, or databases. If we are on the scratch mode, no services are configured by default. Eventually, we may by able to install projects via mc_project. A project is just a classical code repository which has a \u0026ldquo;.salt\u0026rdquo; and/or ansible playbooks/roles folder commited with enougth information on how to deploy it. Registries The configuration of any of the formulas (nodetypes, controllers, localsettings, services) is handled via Makina-States registries. History Makina-States was first using the salt HighState principle of configuring everything. was based at fist on nodetypes presets that were preselected collections of salt states to apply to the system This is from where the highstate will start to run. Recently we cutted off this behavior, and now you must apply them explicitly. Indeed: highstate tend to grow and when you decide to reapply it you may accidentaly deliver things you forgotten of. It\u0026rsquo;s long, very long to wait to reapply everything for small changes.",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/layout/",
  "section": "reference",
  "title": "Layout",
  "type": "reference",
  "description": "",
  "content": "Layout Relative to the top makina-states clone folder. bin/ansible - wrapper to ansible bin/ansible-galaxy - wrapper to ansible-galaxy bin/ansible-playbook - wrapper to ansible-playbook bin/salt-call - wrapper to salt-call ansible/ - ansible plays, roles, modules \u0026 etc etc/ - configuration etc/ansible/ - ansible configuration etc/salt/ - saltstack configuration etc/makina-states/ - makina-states configuration pillar/ - saltstack pillar files pillar/pillar.d/ - saltstack pillar files (global) pillar/private.pillar.d/ - saltstack pillar files (for the current node) pillar/.pillar.d/ - saltstack pillar files (for a specific minion) salt/makina-states/ - saltstack states makina-states/ - makina-states saltstack states salt/_modules/ - custom salt modules salt/_pillar/ - custom extpillar modules Salt pillar Saltstack configuration is based on pillars. To facilitate configuration of the Top file, we added those features: Any JSON file can be used as pillar data. Any SLS/json file dropped inside pillar/pillars.d/ will be loaded for all minion as pillar data Any SLS/json file dropped inside pillar/private.pillars.d will be only loaded for the current node of operation. Any SLS/json file dropped inside pillar/\u0026lt;$minionid\u0026gt;.pillars.d will be only loaded for the \u0026ldquo;\\$minionid\u0026rdquo; host Salt + Ansible bridge notes Makina-states has better to use an ansible dynamic inventory that bridges the salt pillar with ansible via a salt module: mc_remote_plllar. This module is pluggable and will search in the salt modules installed those who have declared special named functions: get_masterless_makinastates_hosts() return a list of host to manage get_masterless_makinastates_groups(minionid, pillar) return a list of groups for the specific minion id For each host found by all get_masterless_makinastates_hosts functions: Get its pillar by calling mc_remote_pillar.get_pillar($host) Extract/generate from informations in the pillar relevant ansible host vars for this minion. saltpillar ansible hostvar is the pillar of this minion. Generate ansible groups from those hostvars by calling eac get_masterless_makinastates_groups function By default, we use the mc_pillar ext pillar which loads a file: etc/makina-states/database.sls which describe our infractructure and this will: list all nodes that are configured as ansible targets generate pillar info for all nodes (and per se fall inside the ansible inventory of those related hosts. Custom extpillar In other words, to add your custom way of managing your hosts: Create an ext_pillar to complete the pillar for a specific minion depending on its minion id and that\u0026rsquo;s why the easiest way is to adopt a minionid/hostname naming scheme. Create a module that implement the get_masterless_makinastates_hosts \u0026amp;\u0026amp; get_masterless_makinastates_groups functions register the pillar and module to the local makina-states installation (see bellow) Take example on: module : (search for get_masterless_makinastates_groups \u0026amp;\u0026amp; get_masterless_makinastates_hosts extpillar To load your extpillar, you ll have to add it to the local salt configuration. You can add a file this way $WC/etc/salt/minion.d/99_extpillar.conf ext_pillar: - mc_pillar: {} - mc_pillar_jsons: {} - mycustompillar: {} To load your custom module, place it under $WC/salt/_modules To load your custom pillar, place it under $WC/salt/_pillar Verify the pillar for a minion Use this command: bin/salt-call mc_remote_pillar.get_pillar \u0026lt;minion_id\u0026gt; Verify the groups for a minion Use this command: bin/salt-call mc_remote_pillar.get_groups \u0026lt;minion_id\u0026gt; (OPTIONAL) Add a cron to speed up pillar generation To generate regularly the cron for all the configured minion, to speed up regular ansible calls (the pillar will already be cached at the call time), you can register a cron that does that. /etc/cron.d/refresh_ansible 15,30,45,00 * * * * root /srv/makina-states/_scripts/refresh_makinastates_pillar.sh",
  "subtitle":"",
  "tags": ["topics","ansible"]
  }
,{
  "url": "/reference/databasesls/",
  "section": "reference",
  "title": "database.sls",
  "type": "reference",
  "description": "",
  "content": "For configuring a single machine, you can rely on a local crafted pillar, but to operate on a cluster, it would be a lot more cumbersome and not DRY. Fir this we created mc_pillar, an ext_pillar that describe a whole cluster infrastructure from a single SLS file. This special file, etc/makina-states/database.sls. will describe our infrastructure and specially how to access to the remote systems. At first, you will need to copy etc/makina-states/database.sls.in which is a sample, and adapt it to your needs: cp etc/makina-states/database.sls.in \\ etc/makina-states/database.sls $EDITOR etc/makina-states/database.sls The contents of the file is mostly self explainatory. This file is then parsed by the mc_pillar module (called via an extpillar hook) to get the appropriate pillar for a specific minion id. This pillar aims to grab a good part of its system configuration from backups to ssl, to cloud configuration and so on. We heavyly rely on memcached to improve the performance, so first please install it this way: bin/salt-call -lall state.sls makina-states.services.cache.memcached Verify the pillar for a minion after a database.sls change Use this command: service memcached restart bin/salt-call mc_pillar.ext_pillar \u0026lt;minion_id\u0026gt;",
  "subtitle":"",
  "tags": ["topics","minions","databasesls"]
  }
,{
  "url": "/topics/ssl/",
  "section": "topics",
  "title": "Manage ssl certificates",
  "type": "topics",
  "description": "",
  "content": "General use Management is done via the pillar, and via the makina-states.localsettings.ssl sls. After configuration, apply it to your system via bin/salt-call -l all state.sls makina-states.localsettings.ssl Or via ansible (remote host):: ANSIBLE_TARGETS=\u0026quot;$hostname\u0026quot; bin/ansible-playbook \\ ansible/plays/saltcall.yml -e saltargs makina-states.localsettings.ssl Add a certificate to the system trust system (add a \u0026lsquo;ca\u0026rsquo;) pillar/pillar.d/cert.sls # \u0026lt;CN\u0026gt; makina-states.localsettings.ssl.cas.foobar: | -----BEGIN CERTIFICATE----- MIIDejCCAmKgAwIBAgICA+gwDQYJKoZIhvcNAQELBQAwfzELMAkGA1UEBhMCRlIx DDAKBgNVBAgMA1BkTDEPMA0GA1UEBwwGTmFudGVzMRYwFAYDVQQKDA1NYWtpbmEg Q29ycHVzMQ8wDQYDVQQDDAZmb29iYXIxKDAmBgkqhkiG9w0BCQEWGWNvbnRhY3RA bWFraW5hLWNvcnB1cy5jb20wIBcNMTYwNTA0MTA0NjAzWhgPMzAzNDExMDQxMDQ2 MDNaMH8xCzAJBgNVBAYTAkZSMQwwCgYDVQQIDANQZEwxDzANBgNVBAcMBk5hbnRl czEWMBQGA1UECgwNTWFraW5hIENvcnB1czEPMA0GA1UEAwwGZm9vYmFyMSgwJgYJ KoZIhvcNAQkBFhljb250YWN0QG1ha2luYS1jb3JwdXMuY29tMIIBIjANBgkqhkiG 9w0BAQEFAAOCAQ8AMIIBCgKCAQEAnLYWB4f9lRVc/fbqOvOCNTCefWnNwKehyf9z LKzZ93ki5bHYLKUoI7tWK2UOKNbnADhEfgGiWNcGtdrr9wc4FFLFR43tUfIxMfqe wUcsv06V9IsmIP4Pi+knAPZG5fXystlPfLjom4bCx5mQr2SGIijw2ogYHKAIdgZJ rviDWM2XIbdEx0TIqkOAokKqUtDr8ZEG289P5v5mrHjacAC8GzhxCgg1RWmaJOhW jc6bfdgLEOQCwt3hE92r+qrh0JjxBINVLE6IO8dL1jGxN8O+U/sQdhDvuN1bwyXd 8117+FSP8C+nnOK37MI27qv0D+sEZXZXAdEAY6w0WF4EAuY/kwIDAQABMA0GCSqG SIb3DQEBCwUAA4IBAQBHG6MkNhaeXWqMqzcYmLWZQZ6hONfRaK7lZlKmly6yVzLJ Y6v5wPMtWDzE0ALS0K2nhG4dEuEo1D1/dQhdz+zmJC5+xVnCzzWIxfNs0GgQMTVj eEmp3Hl0QBwe66swFaMKPz9+1eiQKaTE4pcwOXGEFwephaJWkswX4Fw0o9CA7NLl z0uIpHB12tcGlxS7joraj6aV4nKj+T3xVzsQqR2x5jbZMzsn/1W4afeSKZkBWiNI Z1cASST8OvDiBkQna7LNqDVfogezK0h/8Wbqp5dipeNIY9xu/L4Hr9+Djb9mOwp+ gKtKM4seNltkeKgYrupAUecK3Rs+xiF9j5xiv2X1 -----END CERTIFICATE----- Add a certificate and it\u0026rsquo;s key for reuse in makina-states packages applications The certicate can be either a selfsigned certificate or a certificate and its authority chain with the certificate itself comes first pillar/pillar.d/cert.sls # \u0026lt;CN\u0026gt; makina-states.localsettings.ssl.certificates.titi: - | -----BEGIN CERTIFICATE----- MIIDdjCCAl6gAwIBAgICA+gwDQYJKoZIhvcNAQELBQAwfTELMAkGA1UEBhMCRlIx DDAKBgNVBAgMA1BkTDEPMA0GA1UEBwwGTmFudGVzMRYwFAYDVQQKDA1NYWtpbmEg Q29ycHVzMQ0wCwYDVQQDDAR0aXRpMSgwJgYJKoZIhvcNAQkBFhljb250YWN0QG1h a2luYS1jb3JwdXMuY29tMCAXDTE2MDUwNDExMDcxNFoYDzMwMzQxMTA0MTEwNzE0 WjB9MQswCQYDVQQGEwJGUjEMMAoGA1UECAwDUGRMMQ8wDQYDVQQHDAZOYW50ZXMx FjAUBgNVBAoMDU1ha2luYSBDb3JwdXMxDTALBgNVBAMMBHRpdGkxKDAmBgkqhkiG 9w0BCQEWGWNvbnRhY3RAbWFraW5hLWNvcnB1cy5jb20wggEiMA0GCSqGSIb3DQEB AQUAA4IBDwAwggEKAoIBAQDMRnNmGHdSfjmv/HQSLKQ0aIhukNQJP1/pVYfoHN/X BE5pbbM3voZaecq5puJV1CAojYO9XkIY6FFOQnXbr+285ectuTHFHGTQpw/cEtUd uHR7SXdhcfFOMw2og/WcdiOj5+WqEkm5hsT5QWMFTYQxXsRtwWVxx9JzBSStPpzi aJ1bfg51F+iEFvnkAsYN6++CAGp93pKNhKKyPx52fiiSwVH5+7Iouw5BzX68DQK5 1i2YoHDRKdZmBJ/wVUgISsuHEf4JhKMfyiQWvfjqNL5FQx4nEnhHbcrYr+/h/2+A 7IdscdbpQa4mKK6+5B9EIjR/c/6LKmXhaQuNwg+UaP9JAgMBAAEwDQYJKoZIhvcN AQELBQADggEBAB/egp+ifuMfl7tFiRiO95QeIu6YLNSs6l2ZQ8uHSqlQ6/8GSq/J C1vt/yy4nPZ/14AonlIxWiKMH/1I96Y7W/8KZ5v9DbYsjGwO1TwqNxsqxjjMlW4g Qb1L4vnAq+25HhX0M1xiJWErgPfzMCVTyOhhuVaIPVTZUBhN5GsVtzuzeC4Vpg1O wAhBRgbyi9gxdWoxeaujColAoiwBYgLt6d+jg7I7RSYvd6bIixc00G0J4zY0d8jB ztK3UXbf4G0Bt7R/DcyZ0Tsp51+d5vpD+UjKkpijwhDkUGNC1ljD5M95NlmbCPdp 5ODKbWRuHLcUyzEAjzplwC6FpAlvN11SanA= -----END CERTIFICATE----- - | -----BEGIN PRIVATE KEY----- MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDMRnNmGHdSfjmv /HQSLKQ0aIhukNQJP1/pVYfoHN/XBE5pbbM3voZaecq5puJV1CAojYO9XkIY6FFO QnXbr+285ectuTHFHGTQpw/cEtUduHR7SXdhcfFOMw2og/WcdiOj5+WqEkm5hsT5 QWMFTYQxXsRtwWVxx9JzBSStPpziaJ1bfg51F+iEFvnkAsYN6++CAGp93pKNhKKy Px52fiiSwVH5+7Iouw5BzX68DQK51i2YoHDRKdZmBJ/wVUgISsuHEf4JhKMfyiQW vfjqNL5FQx4nEnhHbcrYr+/h/2+A7IdscdbpQa4mKK6+5B9EIjR/c/6LKmXhaQuN wg+UaP9JAgMBAAECggEAPkn9RlSPjggPbyp7+k7Cg3icoZpoDanVhUEfgBfN6bLW di+NRqJCNbSNrK7GtYVJiRQd59CmNxIgOMzrQ2ISDFfOdpLSKljOJRHMND9J3RYx 7qYoUP59pmrK72fNrTgZBhHgZkvNT1VZGuhlWWiZtrQ/EXi3hkp4UbpvxKQjEqZn o2+vbUYh440dKdw+iJnDAYZi/1yFCqiIxkWUSFFky8gjppQ7CBeQ4LEHKPodd4A2 ccnK8op6H5n26Xqdi65G0SR+X39xtEGp8pzUQW8XaXCjEtBNhD95ymGXEmq8KfqG XcN6nBMVp5V9X4+xFg2hBsFPsL6xrT7deASBKyDQAQKBgQD9VG8okA1rd11ttyvi DhIV6PlYBxhEex4lGeqOrjETKMsAFDsJ5Ntlr3MiXiLIuQ0pAcu3tpxNEkTLkcHo e0VpP7HCr14vnCpZyB1B8wTmbBJVMXkD+oaN7pzEJhauaombfDRH4NKd87lgveLG 3x/CFHdJfEvxwjRdpER+ZxJvIQKBgQDObaa9WcyZnuB7R109TTiZgSGo1XljF1m9 Ji+85sSdV1mHnUyghgszbnW5s8dM1sweY5ZAONFsF9j06iL2h1XnGlgKHBL22UGH o5nc5/oHfuc/YmRdSUCgmwSZixrInFjfvUiE/tR/j4z2AnpEB4/8genEm+elXYIE uodJpj3TKQKBgQChY+FNXjiudmU3OLLkWUJ8Yug3hI2ZUzZpPJGKRL9PDXYGntzd +MctiRE4m/BdIEeaEGLQr630C+d4KWv3yFD4NHPzK/Y9LqhsemjpUwGUKtWjINmQ B1MhqRqGfB2HEKiKPh6wjDKiHlvDnjWTrSJ2asN0NZPMeYUTA0v/m3rLAQKBgFJZ K8sdp6Eg4CxNq8RoqcuS1/qiLmp5RjNOqHyTEpwx3GVdOtROpOk/h3ctYLQmfAcj cyzrfZ/BY6tQO+Jc2sf2mmhuCqKuyJVzjk2xvOyAk3+VoLQWJNHtBUi7VVPyCwI2 YFet0NeSTIlXM68v1SDGMptcFmzBgLyiLJYU21UBAoGBAIhSvpsw3z/gAf9nbciZ 9puJiPqFBld7DrCp69iaD/ryXzLfzwI3bzWR8M8TuBO6DxApiYx7Zps4QabPQZTN U4UFg0AcdRh27OUXYtGENw7W0ssZKhlII78WB+0haAwe+kQJ4aNpF0eqWXLH7thR zKKdzi+lMlG5NimeR246wBvX -----END PRIVATE KEY----- Add certificates via the makina-states ext_pillar When using mc_pillar deployment, edit your local etc/makina-states/database.sls Take an example on the database.sl ssl \u0026amp; ssl_certs section. The ssl_certs section is a mapping id / tuples of (certicate, key) mappings. certicate can be either a selfsigned certificate or a certificate and all the authority, where the certificate of the common name comes first. The ssl section is where you will map certificates described in the ssl_certs section to a particular minion id. Remember that the special default section has the purpose to map certificate to any minion You can add either certificates for a host by specifying them by the id index or configure infra wide certs by setting them in the default section. Reconfigure the SSL system bin/salt-call -lall state.sls makina-states.localsettings.ssl Use the ssl macro in a state to register a certificate This add the certificate inside the cloud ssl directories Then also may add it to the systemwide ssl trust foo.sls: {% import \u0026quot;makina-states/localsettings/ssl/macros.jinja\u0026quot; as ssl with context %} {{ ssl.install_certificate( cert_string [, [cert_key_string]] [, trust=True/False]] )}} Parameters: cert_string : either a certificate string (full certificate in PEM format) or a path to load a certificate in PEM format or a key inside the mc_ssl.settings.certificates regitry (if you need an authority chain, place the certificate first) cert_key_string (optional) : in case of cert_string is neither a certificate inline or a certificate filepath, this will lookup inside the pillar for a matching certificate inside the mc_ssl.settings.certificates key. trust (optional) : boolean to tell to register the certificate to the system-wide ssl trusted certe",
  "subtitle":"",
  "tags": ["topics","ssl"]
  }
,{
  "url": "/reference/registries/",
  "section": "reference",
  "title": "Registries \u0026 Configuration",
  "type": "reference",
  "description": "",
  "content": "We needed a way, in our salt states: To deduplicate the cumbersome handling of variables To make cleaner jinja code For a configuration knob, aggregate values from difference sources, by precedence. For this, we decided to abstract this in python code So, a registry in the Makina-States vocabulary is a salt execution module that returns a python dictionnary: containing various configuration knobs with sane defaults overridable at will by the user via the pillar or the grains. The idea was then to use dedicated saltstack execution modules to provide a way to have dictionnaries of data aggregated with this precedence: Pillar (pillar) Grains (grains) Configuration of the minion (opts) Configuration of the minion (opts[\u0026lsquo;master]\u0026rsquo;]) Exemples: mc_apache mc_nginx mc_mysql Those registries rely on an heavily used function mc_utils.default that will do the job of gathering for the configuration prefix all the knobs from the various pieces of data we want (pillar, grains, opts) Thus, by example, you want to install the mysql service: You will use this sls: bin/salt-call -linfo --retcode-passthrough \\ state.sls makina-states.servies.db.mysql Reading the code of mysql formula, you see that it calls mc_mysql To override the port (default: 3306), you can do this in the pillar or the grains those ways Flat Method(preferred): pillar/pillar.d/mysql.sls makina-states.services.db.mysql.port: 3306 Nested Method: pillar/pillar.d/mysql.sls makina-states.services.db.mysql: port: 3306",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/topics/haproxy/",
  "section": "topics",
  "title": "Haproxy",
  "type": "topics",
  "description": "",
  "content": "the formula is in salt/makina-states/services/proxy/haproxy Idea We provide a facility to auto configure HTTP/HTTPS/REDIS/TCP backends via the informations that we can discover in the pillar. We want in an future iteration to add a discovery mecanism, maybe via the mine or a discovery service like ETCD, zookeeper or consul. The subkey for configuring proxies is the makina-states.haproxy_registrations top dictionnary. How to use Extra HAPROXY configuration can be done by overriding the default registry, mc_haproxy.settings via the makina-states.services.proxy.haproxy prefix as usual. Look available tweaks by calling salt-call mc_haproxy.settins. After, add makina-states.haproxy_registrations.* entries to add proxies. ssl is used and reused from makina-states.localsettings.ssl First, activate haproxy and run the states a first time: bin/salt-call -lall state.sls makina-states.services.proxy.haproxy The most complete form to register a minion with haproxy is as follow makina-states.haproxy_registrations.\u0026lt;arbitrar id\u0026gt;: - ip: \u0026lt;local_ip of backend\u0026gt; frontends: \u0026lt;frontend_port\u0026gt;: to_port: \u0026lt;dest_port\u0026gt;, # optional, default to \u0026lt;frontend_port\u0026gt; mode: \u0026lt;http/https/tcp/tcps/redis\u0026gt; hosts: [\u0026lt;hosts_to_proxy_from\u0026gt;] # only useful on http(s) mode regexes: [\u0026lt;hosts_to_proxy_from\u0026gt;] # only useful on http(s) mode wildcards: [\u0026lt;hosts_to_proxy_from\u0026gt;] # only useful on http(s) mode This declaration will help on the haproxy minion side be to configure appropriate haproxy frontends and backends objectds. Notes: The ip is the local ip of the minion to proxy requests to Frontends is a dictionnary of ports / metadata describing how to configure haproxy to proxy to the minion: mode is node the haproxy mode but a switch for us to know how to proxy requests. http/https Proxy HTTP(s) requests, depending on an additionnal regexes/wildcards/hosts knob regexes list of regexeses to match in the form [host_regex, PATH_URI_regex] wildcards list to strings which insensitive match if the header HOST endswith hosts list to strings which insensitive match exactly the header HOST tcp/tcps configure a tcp based proxy, here regexes/wildcards/hosts is useless. Be warn, main_cert will be the served ssl certicated as no SNI is possible redis configure a redis frontend (tcp based, so also no use of regexes/wildcards/hosts) based on https://support.pivotal.io/hc/en-us/articles/205309388-How-to-setup-HAProxy-and-Redis-Sentinel-for-automatic-failover-between-Redis-Master-and-Slave-servers to_port can be used to override the port to proxy on the minion side if it is not the same that on haproxy side If frontends are not specificied, you need to specify ip and one of hosts/regexes/wildcards as we default to configure http \u0026amp; https proxies. If frontends are specified, you need to respecify all of them, no default will be used in this case. 80 \u0026amp; 443 frontend port modes default to respectivly http \u0026amp; https. By default, if no frontends are specified, we setup http \u0026amp; https frontends. The SSL backend will try for forward first on 443, then on 80. Acls order for http mode is not predictible yet and will be difficult. Prefer to use a sensible configuration for your case rather than complicating the ACLS generation algorythm. proxy If we have a minion haproxy1 and want to proxy to myapp2-1 on http \u0026amp; https when a request targeting \u0026ldquo;www.super.com\u0026rdquo; arrise. all we have to do is to in haproxy1 pillar: makina-states.haproxy_registrations.haproxy1: - ip: 10.0.3.14 hosts: [www.super.com] wildcard Wilcards are also supported via the wildcards key makina-states.haproxy_registrations.haproxy1: - ip: 10.0.3.14 wildcards: [\u0026#39;*.www.super.com\u0026#39;] regex regex is also supported via the regexes key makina-states.haproxy_registrations.haproxy1: - ip: 10.0.3.14 regexes: [\u0026#39;my.*supemyappost.com\u0026#39;, \u0026#39;^/api\u0026#39;] if we want to proxy http to port \u0026ldquo;81\u0026rdquo; of myapp2-1 \u0026amp; https to 444 makina-states.haproxy_registrations.haproxy1: - ip: 10.0.3.14 hosts: [www.super.com] frontends: 80: {to_port: 81} 443: {to_port: 444} redis We have a special redis mode to do custom health checks on a redis cluster Short form if you use the default port on both ends: makina-states.haproxy_registrations.haredis: - ip: 10.0.3.14 # localip of myapp2-1 frontends: 6378: {} Long forms makina-states.haproxy_registrations.haredis: - ip: 10.0.3.14 frontends: 66378: {to_port: 666, mode: redis} 6378: {mode: redis} Redis auth is supported this way makina-states.haproxy_registrations.haredis: - ip: 10.0.3.14 frontends: 6378: {password: \u0026quot;foobar\u0026quot;, mode: redis} rabbitmq We have a special rabbitmq mode to set sane options on backend for rabbitmq Short form if you use the default port on both ends: makina-states.haproxy_registrations.haredis: - ip: 10.0.3.14 frontends: 5672: {} Long forms makina-states.haproxy_registrations.haredis: - ip: 10.0.3.14 frontends: 55672: {to_port: 333, mode: rabbitmq} 5672: {mode: rabbitmq} Register 2 backends for one same frondend makina-states.haproxy_registrations.mc_cloud_http1\u0026quot;: - \u0026quot;ip\u0026quot;: \u0026quot;10.5.5.2\u0026quot; \u0026quot;hosts\u0026quot;: [\u0026quot;es2.devhost5-1.local\u0026quot;] \u0026quot;frontends\u0026quot;: \u0026quot;80\u0026quot;: \u0026quot;mode\u0026quot;: \u0026quot;http\u0026quot; makina-states.haproxy_registrations.mc_cloud_http2\u0026quot;: - \u0026quot;ip\u0026quot;: \u0026quot;10.5.5.666\u0026quot; \u0026quot;hosts\u0026quot;: [\u0026quot;es2.devhost5-2.local\u0026quot;] \u0026quot;frontends\u0026quot;: \u0026quot;80\u0026quot;: \u0026quot;mode\u0026quot;: \u0026quot;http\u0026quot;",
  "subtitle":"",
  "tags": ["topics","cloud","haproxy"]
  }
,{
  "url": "/reference/nodetypes/",
  "section": "reference",
  "title": "Nodetypes",
  "type": "reference",
  "description": "",
  "content": "Nodetypes Your choice for nodetype is one of: scratch (default) : only manage the ansible/salt installation and configuration. You ll want to activate this mode if you want to apply explicitly your states without relying of default nodetypes configuration. server : matches a baremetal server, and manage it from end to end (base packages, network, locales, sshd, crond, logrotate, etc, by default) vm : VM (not baremetal), this is mostly like server lxccontainer : matches a lxc container mostly like server but install and fix lxc boot scripts laptop : mostly like server but also install packages for working on a developement machine (prebacking a laptop for a dev dockercontainer : matches a VM (not baremetal), this is mostly like server, but install \u0026amp; preconfigure circus to manage daemons. devhost : development machine enabling states to act on that, by example installation of a test local-loop mailer. vagrantvm : flag vagrant boxes and is a subtype of devhost You can tell boot-salt2.sh which nodetype to use via the --nodetype switch boot-salt2.sh --nodetype server --reconfigure Switching to another nodetype on an already installed environment If you installed the scratch preset and want to switch to another preset: salt-call state.sls makina-states.nodetypes.\u0026lt;your_new_preset\u0026gt; If you installed a preset and want to switch to another preset: edit etc/makina-states/nodetype and put your new preset edit etc/makina-states/nodetypes.yaml and set to false your old preset Finally, run: salt-call state.sls makina-states.nodetypes.\u0026lt;your_new_preset\u0026gt; And finally: boot-salt2.sh --nodetype \u0026lt;your_new_preset\u0026gt; --reconfigure",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/controllers/",
  "section": "reference",
  "title": "Controllers",
  "type": "reference",
  "description": "",
  "content": "controllers states purpose is mainly to check: our bundled salt \u0026amp; ansible binaries are ready for operation the cloned code is up to date and clean If the user selected them: crons are in place install links (/usr/local/bin) are present RollingRealse updater crons are in place",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/localsettings/",
  "section": "reference",
  "title": "LocalSettings",
  "type": "reference",
  "description": "",
  "content": "LocalSettings states are related to the low level configuration of an environment EG: locales network low level configuration](hardrive, etc) installing compilers \u0026amp; language interpreters configuring base tools \u0026amp; editors configuring SSH client distributing SSL certificates If any other preset than scratch has been activated, Many localsettings will be applied by default, see mc_localsettings:registry States localsettings States non exhaustive shortcuts: State State State State localsettings/apparmor localsettings/nodejs localsettings/hostname localsettings/sudo localsettings/autoupgrade localsettings/npm localsettings/hosts localsettings/sysctl localsettings/casperjs localsettings/nscd localsettings/init.sls localsettings/systemd localsettings/check_raid localsettings/phantomjs localsettings/insserv localsettings/timezone localsettings/desktoptools localsettings/pkgs localsettings/jdk localsettings/updatedb localsettings/dns localsettings/python localsettings/ldap localsettings/users localsettings/editor localsettings/reconfigure-network localsettings/locales localsettings/vim localsettings/env localsettings/repository_dotdeb localsettings/localrc localsettings/mvn localsettings/etckeeper localsettings/rvm localsettings/grub localsettings/ssl localsettings/git localsettings/screen localsettings/golang localsettings/shell localsettings/groups localsettings/sshkeys",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/services/",
  "section": "reference",
  "title": "Services",
  "type": "reference",
  "description": "",
  "content": "Salt States dedicated to install services on the targeted environment States services States non exhaustive shortcuts: backup State State services/backup/bacula services/backup/dbsmartbackup services/backup/burp services/backup/rdiff-backup base State State services/base/cron services/base/ntp services/base/dbus services/base/ssh services/cache/memcached misc State State services/collab/etherpad services/queue/rabbitmq services/sound/mumble services/ftp/pureftpd db State State services/db/mongodb services/db/postgresql services/db/mysql services/db/redis dns State State services/dns/dhcpd services/dns/slapd services/dns/bind firewall State State services/firewall/shorewall services/firewall/firewalld services/firewall/firewall services/firewall/ms_iptables services/firewall/fail2ban services/firewall/psad gis State services/gis/postgis services/gis/ubuntugis http State State services/http/nginx services/http/apache_modfastcgi services/http/apache services/http/apache_modfcgid services/java/tomcat services/http/apache_modproxy log State State services/log/rsyslog services/log/ulogd Mail State State services/mail/dovecot services/mail/postfix Monitoring State State services/monitoring/client services/monitoring/icinga_web2 services/monitoring/icinga services/monitoring/nagvis services/monitoring/icinga2 services/monitoring/pnp4nagios services/monitoring/icinga_web services/monitoring/snmpd php State State services/php/common services/php/modphp services/php/phpfpm services/php/phpfpm_with_apache services/php/phpfpm_with_nginx Proxy State State services/proxy/haproxy services/proxy/uwsgi virt State State services/virt/docker services/virt/kvm services/virt/lxc services/virt/virtualbox",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/servicesmanagers/",
  "section": "reference",
  "title": "Services Managers",
  "type": "reference",
  "description": "",
  "content": "In makina-states services managers act on top of services to manage their lifecycle (start/stop/restart/reload). systemd circus supervisor",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/macros/",
  "section": "reference",
  "title": "Macros",
  "type": "reference",
  "description": "",
  "content": "Here are a non exhaustive list of macros that makina-states provides and you may use in your states. Helpers h(helpers) deliver_deliver_config_files: push configuration files service_restart_reload: aim to restart or reload service but handle the case where services mis implement the status function and mess salt modules. toggle_service: helper to call service_restart_reload nginx nginx nginx.vhost apache apache apache.vhost php php php.fpm_pool php.minimal_index php.toggle_ext mysql macros mysql_db mysql_group postgresql macros postgresql_db postgresql_user postgresql_group install_pg_exts install_pg_ext circusd macros circusAddWatcher supervisord macros supervisorAddProgram mongodb macros mongodb_db mongodb_user uwsgi macros config rabbitmq macros rabbitmq_vhost",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/projects/",
  "section": "reference",
  "title": "Projects",
  "type": "reference",
  "description": "",
  "content": "List of templates for inspiration Templates",
  "subtitle":"",
  "tags": ["reference","installation"]
  }
,{
  "url": "/reference/templates/",
  "section": "reference",
  "title": "Templates",
  "type": "reference",
  "description": "",
  "content": "Those projects can be used as-is or as a kickstarter for your own projects based on makina-states either by copying or inspiring yourself to create your own Project skeletons compliant with makina-states corpus-drupal corpus-php corpus-django corpus-zope-plone corpus-staticwww databases corpus-solr corpus-mysql corpus-elasticsearch corpus-mongodb corpus-rabbitmq corpus-pgsql webapps corpus-seafile corpus-redmine corpus-vaultier corpus-fusiondirectory corpus-sabnzbd corpus-legacyenketo corpus-odoo corpus-piwik Osm corpus-osmdb corpus-osmrender corpus-tilemill Code \u0026amp; CI corpus-gitlab corpus-jenkins corpus-jenkins-slave corpus-svn corpus-gitlabrunner Misc corpus-mumble corpus-irssi Mail corpus-mailman3",
  "subtitle":"",
  "tags": ["reference","projects","templates"]
  }
,{
  "url": "/tags/ansible/",
  "section": "",
  "title": "Ansible",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/cloud/",
  "section": "",
  "title": "Cloud",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/cloud/",
  "section": "cloud",
  "title": "Cloud Documentation",
  "type": "cloud",
  "description": "",
  "content": "LXC",
  "subtitle":"",
  "tags": ["cloud","lxc"]
  }
,{
  "url": "/tags/databasesls/",
  "section": "",
  "title": "Databasesls",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/haproxy/",
  "section": "",
  "title": "Haproxy",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/install/",
  "section": "",
  "title": "Install",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/installation/",
  "section": "",
  "title": "Installation",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/cloud/lxc/",
  "section": "cloud",
  "title": "LXC containers management",
  "type": "cloud",
  "description": "",
  "content": "workflow: WARNING currently only those backing store are supported/tested: dir overlayfs Go into makina-states folder: cd /srv/makina-states If wanted, edit database, specially vms, \u0026amp; cloud_vm_attrs: vim etc/makina-states/database.sls Define shell variable to copy/paste following commands: export controller=\u0026quot;$(hostname -f)\u0026quot; export cn=\u0026quot;$(hostname -f)\u0026quot; # export cn=\u0026quot;c.foo.net\u0026quot; export vm=\u0026quot;d.foo.net\u0026quot; export vm_tmpl=\u0026quot;makinastates\u0026quot; Preparation on the controller Refresh cache: # bin/salt-call -lall \\ # state.sls makina-states.services.cache.memcached # the first time service memcached restart _scripts/refresh_makinastates_pillar.sh # or with limit on hosts that the run will be ANSIBLE_TARGETS=\u0026quot;$controller,$vm,$cn\u0026quot; _scripts/refresh_makinastates_pillar.sh Preinstalling makina-states (controller \u0026amp; each compute node) Installing it: ANSIBLE_TARGETS=\u0026quot;$cn\u0026quot; bin/ansible-playbook \\ ansible/plays/makinastates/install.yml Configure the dns on a full makina-states infra with mc_pillar ANSIBLE_TARGETS=\u0026quot;$controller\u0026quot; bin/ansible-playbook \\ ansible/plays/cloud/controller.yml Compute node related part Configure compute_node with: ANSIBLE_TARGETS=\u0026quot;$cn\u0026quot; ansible-playbook \\ ansible/plays/cloud/compute_node.yml Cooking and delivery of container / container templates Initialise a lxc container that will be the base of our image (after creation go edit in it until sastified of the result): ANSIBLE_TARGETS=\u0026quot;$controller,lxc$vm_tmpl\u0026quot; bin/ansible-playbook \\ ansible/plays/cloud/create_container.yml Synchronise it to an offline image, this will copy the container to the image, and remove parts from it (like sshkeys) to impersonate it: ANSIBLE_TARGETS=\u0026quot;$controller\u0026quot; bin/ansible-playbook \\ ansible/plays/cloud/snapshot_container.yml -e \u0026quot;lxc_template=$vm_tmpllxc_container_name=lxc$vm_tmpl\u0026quot; Arguments: ANSIBLE_TARGETS : compute node where the container resides (must be in ansible inventary) lxc_template : lxc image to create lxc_container_name : lxc container which serve as a base for the image Transfer the template to the compute node where you want to spawn containers from that image: ANSIBLE_TARGETS=\u0026quot;$cn\u0026quot; ansible-playbook \\ ansible/plays/cloud/sync_container.yml \\ -e \u0026quot;lxc_orig_host=$controllerlxc_container_name=$vm_tmpl\u0026quot; Arguments: ANSIBLE_TARGETS : both orig and dest lxc_host : where to transfer container/template lxc_orig_host : where from transfer container/template lxc_container_name : lxc container to transfer Initialise a container Initialise and finish the container provisioning (from scratch) ANSIBLE_TARGETS=\u0026quot;$cn,$vm\u0026quot; bin/ansible-playbook \\ ansible/plays/cloud/create_container.yml Arguments: ANSIBLE_TARGETS : compute node where the container resides (must be in ansible inventary) \u0026amp; lxc container to create lxc_from_container : lxc container from which initing the container lxc_backing_store : (opt) backing store to use Initialise and finish the container provisioning (from template): ANSIBLE_TARGETS=\u0026quot;$cn,vm\u0026quot; bin/ansible-playbook \\ ansible/plays/cloud/create_container.yml -e \u0026quot;lxc_from_container=$vm_tmpl\u0026quot; Special case: use overlayfs to create the container: ANSIBLE_TARGETS=\u0026quot;$cn,$vm\u0026quot; bin/ansible-playbook \\ ansible/plays/cloud/create_container.yml \\ -e \u0026quot;lxc_from_container=$vm_tmpllxc_backing_store=overlayfs\u0026quot;",
  "subtitle":"",
  "tags": ["cloud","lxc"]
  }
,{
  "url": "/tags/lxc/",
  "section": "",
  "title": "Lxc",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/minions/",
  "section": "",
  "title": "Minions",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/reference/preamble/",
  "section": "reference",
  "title": "Preamble",
  "type": "reference",
  "description": "",
  "content": "Briefing MakinaStates at a whole is a combination of ansible and salt aiming at operating a cluster from baremetal to projects delivery. Note that makina-states do not use regular salt daemons(minion/master) to operate remotely but an ansible bridge that copy the pillar and use salt-call locally directly on the remote box via SSH Ansible get the information from makinastates by getting the salt pillar for a particular through a custom dynamic inventory. Compatibility For now, you will have to use Ubuntu \u0026gt;= 14.04. Makina-States can be ported to any linux based OS, but we, here, use ubuntu server and this is the only supported system for now. It can be used in any flavor: lxc, docker, baremetal, kvm, etc.",
  "subtitle":"",
  "tags": ["topics","installation"]
  }
,{
  "url": "/tags/projects/",
  "section": "",
  "title": "Projects",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/reference/",
  "section": "",
  "title": "Reference",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/reference/",
  "section": "reference",
  "title": "Reference",
  "type": "reference",
  "description": "",
  "content": "See here",
  "subtitle":"",
  "tags": ["topics","installation"]
  }
,{
  "url": "/tags/salt/",
  "section": "",
  "title": "Salt",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/ssl/",
  "section": "",
  "title": "Ssl",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/",
  "section": "",
  "title": "Tags",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/templates/",
  "section": "",
  "title": "Templates",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/topics/",
  "section": "",
  "title": "Topics",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/topics/",
  "section": "topics",
  "title": "Topics",
  "type": "topics",
  "description": "",
  "content": "haproxy SSL",
  "subtitle":"",
  "tags": ["topics"]
  }
,{
  "url": "/tags/upgrade/",
  "section": "",
  "title": "Upgrade",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/tags/usage/",
  "section": "",
  "title": "Usage",
  "type": "page",
  "description": "",
  "content": "",
  "subtitle":"",
  "tags": []
  }
,{
  "url": "/usage/",
  "section": "usage",
  "title": "Usage",
  "type": "usage",
  "description": "",
  "content": "Switch makina-states branch To switch on a makina-states branch, like the v2 branch in production: bin/boot-salt2.sh -b v2 Update makina-states local copy To sync makinastates code bin/boot-salt2.sh -C -S Running makinastates in highstate mode To install all enabled makina-states services after having configured your pillar up bin/boot-salt2.sh -n laptop|server|lxccontainer|vm -C \u0026amp;\u0026amp; \\ bin/salt-call --retcode-passthrough state.sls makina-states.top Upgrade Upgrade will: Run predefined \u0026amp; scheduled upgrade code Update makina-states repositories in /srv/salt \u0026amp; /srv/makina-states Update core repositories (like salt code source in /srv/makina-states/src/salt) Do the highstates (salt and masterone if any) bin/boot-salt2.sh -C --S \u0026amp;\u0026amp; \\ bin/salt-call --retcode-passthrough state.sls makina-states.top use ansible \u0026amp; salt Salt Ansible",
  "subtitle":"",
  "tags": ["topics","installation"]
  }
]
